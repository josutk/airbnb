{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd45df4b",
   "metadata": {},
   "source": [
    "* A modelagem irá seguir a arquitetura dos transformers utilizando o Bert multilingual para conseguir inferir todos os idiomas presentes no dataset, todas as informações da arquitetura e treinamento podem ser observadas no CONFIG. Para avaliação o dataset foi divido em folds aplicando o crossvalidation e o melhor modelo seleciona é o que apresenta menor loss sendo esse utilizado na fase de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ceef523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "\n",
    "model_name1 = 'bert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name1, )\n",
    "\n",
    "CONFIG = {\"seed\": 42, \n",
    "          \"epochs\": 3, \n",
    "          \"model_name\": model_name1,\n",
    "          \"train_batch_size\": 20,\n",
    "          \"valid_batch_size\": 2,\n",
    "          \"max_length\": 256,\n",
    "          \"learning_rate\": 1e-4,\n",
    "          \"scheduler\": 'CosineAnnealingLR',\n",
    "          \"min_lr\": 1e-6,\n",
    "          \"T_max\": 500,\n",
    "          \"weight_decay\": 1e-6,\n",
    "          \"n_fold\": 2, \n",
    "          \"n_accumulate\": 1,\n",
    "          \"num_classes\": 1,\n",
    "          \"margin\": 0.5,\n",
    "          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "          \"hash_name\": 'model'\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bdeb632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "df_listing = pd.read_csv('listings.csv')\n",
    "df_listing = df_listing[['id','name','description','neighborhood_overview','review_scores_rating']]\n",
    "df_listing = df_listing.rename(columns={'id':'reviewer_id'})\n",
    "df_reviews = pd.read_csv('reviews.csv')\n",
    "df = df_reviews.merge(df_listing, left_on='listing_id', right_on='reviewer_id')\n",
    "\n",
    "#df = pd.read_csv('train.csv')\n",
    "df['comments'] = df['comments'].astype(str)\n",
    "#df['review_scores_rating'] = df['review_scores_rating'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e6aa22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comments'] = df['comments'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa00919f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2995cd0e84415f92f4f95b51f51b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=356118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import langid\n",
    "from tqdm.notebook import tqdm\n",
    "idoms = []\n",
    "\n",
    "for i in tqdm(df['comments']):\n",
    "    a, b = langid.classify(str(i))\n",
    "    idoms.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1609e4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id_x</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>reviewer_id_y</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>idioms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17878</td>\n",
       "      <td>64852</td>\n",
       "      <td>2010-07-15</td>\n",
       "      <td>135370</td>\n",
       "      <td>Tia</td>\n",
       "      <td>This apartment is in a perfect location -- two...</td>\n",
       "      <td>17878</td>\n",
       "      <td>Very Nice 2Br in Copacabana w. balcony, fast WiFi</td>\n",
       "      <td>Discounts for long term stays. &lt;br /&gt;- Large b...</td>\n",
       "      <td>This is the one of the bests spots in Rio. Bec...</td>\n",
       "      <td>4.68</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17878</td>\n",
       "      <td>76744</td>\n",
       "      <td>2010-08-11</td>\n",
       "      <td>10206</td>\n",
       "      <td>Mimi</td>\n",
       "      <td>we had a really great experience staying in Ma...</td>\n",
       "      <td>17878</td>\n",
       "      <td>Very Nice 2Br in Copacabana w. balcony, fast WiFi</td>\n",
       "      <td>Discounts for long term stays. &lt;br /&gt;- Large b...</td>\n",
       "      <td>This is the one of the bests spots in Rio. Bec...</td>\n",
       "      <td>4.68</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17878</td>\n",
       "      <td>91074</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>80253</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Staying in Max appartment is like living in a ...</td>\n",
       "      <td>17878</td>\n",
       "      <td>Very Nice 2Br in Copacabana w. balcony, fast WiFi</td>\n",
       "      <td>Discounts for long term stays. &lt;br /&gt;- Large b...</td>\n",
       "      <td>This is the one of the bests spots in Rio. Bec...</td>\n",
       "      <td>4.68</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17878</td>\n",
       "      <td>137528</td>\n",
       "      <td>2010-11-12</td>\n",
       "      <td>230449</td>\n",
       "      <td>Orene</td>\n",
       "      <td>In general very good and reasonable price.\\r&lt;b...</td>\n",
       "      <td>17878</td>\n",
       "      <td>Very Nice 2Br in Copacabana w. balcony, fast WiFi</td>\n",
       "      <td>Discounts for long term stays. &lt;br /&gt;- Large b...</td>\n",
       "      <td>This is the one of the bests spots in Rio. Bec...</td>\n",
       "      <td>4.68</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17878</td>\n",
       "      <td>147594</td>\n",
       "      <td>2010-12-01</td>\n",
       "      <td>219338</td>\n",
       "      <td>David</td>\n",
       "      <td>The apt was nice and in a great location only ...</td>\n",
       "      <td>17878</td>\n",
       "      <td>Very Nice 2Br in Copacabana w. balcony, fast WiFi</td>\n",
       "      <td>Discounts for long term stays. &lt;br /&gt;- Large b...</td>\n",
       "      <td>This is the one of the bests spots in Rio. Bec...</td>\n",
       "      <td>4.68</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id      id        date  reviewer_id_x reviewer_name                                           comments  reviewer_id_y                                               name                                        description                              neighborhood_overview  review_scores_rating idioms\n",
       "0       17878   64852  2010-07-15         135370           Tia  This apartment is in a perfect location -- two...          17878  Very Nice 2Br in Copacabana w. balcony, fast WiFi  Discounts for long term stays. <br />- Large b...  This is the one of the bests spots in Rio. Bec...                  4.68     en\n",
       "1       17878   76744  2010-08-11          10206          Mimi  we had a really great experience staying in Ma...          17878  Very Nice 2Br in Copacabana w. balcony, fast WiFi  Discounts for long term stays. <br />- Large b...  This is the one of the bests spots in Rio. Bec...                  4.68     en\n",
       "2       17878   91074  2010-09-06          80253           Jan  Staying in Max appartment is like living in a ...          17878  Very Nice 2Br in Copacabana w. balcony, fast WiFi  Discounts for long term stays. <br />- Large b...  This is the one of the bests spots in Rio. Bec...                  4.68     en\n",
       "3       17878  137528  2010-11-12         230449         Orene  In general very good and reasonable price.\\r<b...          17878  Very Nice 2Br in Copacabana w. balcony, fast WiFi  Discounts for long term stays. <br />- Large b...  This is the one of the bests spots in Rio. Bec...                  4.68     en\n",
       "4       17878  147594  2010-12-01         219338         David  The apt was nice and in a great location only ...          17878  Very Nice 2Br in Copacabana w. balcony, fast WiFi  Discounts for long term stays. <br />- Large b...  This is the one of the bests spots in Rio. Bec...                  4.68     en"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['idioms'] = idoms\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "271de73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id_x</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>reviewer_id_y</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>idioms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17878</td>\n",
       "      <td>64852</td>\n",
       "      <td>2010-07-15</td>\n",
       "      <td>135370</td>\n",
       "      <td>Tia</td>\n",
       "      <td>This apartment is in a perfect location -- two...</td>\n",
       "      <td>17878</td>\n",
       "      <td>Very Nice 2Br in Copacabana w. balcony, fast WiFi</td>\n",
       "      <td>Discounts for long term stays. &lt;br /&gt;- Large b...</td>\n",
       "      <td>This is the one of the bests spots in Rio. Bec...</td>\n",
       "      <td>4.68</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17878</td>\n",
       "      <td>76744</td>\n",
       "      <td>2010-08-11</td>\n",
       "      <td>10206</td>\n",
       "      <td>Mimi</td>\n",
       "      <td>we had a really great experience staying in Ma...</td>\n",
       "      <td>17878</td>\n",
       "      <td>Very Nice 2Br in Copacabana w. balcony, fast WiFi</td>\n",
       "      <td>Discounts for long term stays. &lt;br /&gt;- Large b...</td>\n",
       "      <td>This is the one of the bests spots in Rio. Bec...</td>\n",
       "      <td>4.68</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17878</td>\n",
       "      <td>91074</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>80253</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Staying in Max appartment is like living in a ...</td>\n",
       "      <td>17878</td>\n",
       "      <td>Very Nice 2Br in Copacabana w. balcony, fast WiFi</td>\n",
       "      <td>Discounts for long term stays. &lt;br /&gt;- Large b...</td>\n",
       "      <td>This is the one of the bests spots in Rio. Bec...</td>\n",
       "      <td>4.68</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17878</td>\n",
       "      <td>137528</td>\n",
       "      <td>2010-11-12</td>\n",
       "      <td>230449</td>\n",
       "      <td>Orene</td>\n",
       "      <td>In general very good and reasonable price.\\r&lt;b...</td>\n",
       "      <td>17878</td>\n",
       "      <td>Very Nice 2Br in Copacabana w. balcony, fast WiFi</td>\n",
       "      <td>Discounts for long term stays. &lt;br /&gt;- Large b...</td>\n",
       "      <td>This is the one of the bests spots in Rio. Bec...</td>\n",
       "      <td>4.68</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17878</td>\n",
       "      <td>147594</td>\n",
       "      <td>2010-12-01</td>\n",
       "      <td>219338</td>\n",
       "      <td>David</td>\n",
       "      <td>The apt was nice and in a great location only ...</td>\n",
       "      <td>17878</td>\n",
       "      <td>Very Nice 2Br in Copacabana w. balcony, fast WiFi</td>\n",
       "      <td>Discounts for long term stays. &lt;br /&gt;- Large b...</td>\n",
       "      <td>This is the one of the bests spots in Rio. Bec...</td>\n",
       "      <td>4.68</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id      id        date  reviewer_id_x reviewer_name                                           comments  reviewer_id_y                                               name                                        description                              neighborhood_overview  review_scores_rating idioms\n",
       "0       17878   64852  2010-07-15         135370           Tia  This apartment is in a perfect location -- two...          17878  Very Nice 2Br in Copacabana w. balcony, fast WiFi  Discounts for long term stays. <br />- Large b...  This is the one of the bests spots in Rio. Bec...                  4.68     en\n",
       "1       17878   76744  2010-08-11          10206          Mimi  we had a really great experience staying in Ma...          17878  Very Nice 2Br in Copacabana w. balcony, fast WiFi  Discounts for long term stays. <br />- Large b...  This is the one of the bests spots in Rio. Bec...                  4.68     en\n",
       "2       17878   91074  2010-09-06          80253           Jan  Staying in Max appartment is like living in a ...          17878  Very Nice 2Br in Copacabana w. balcony, fast WiFi  Discounts for long term stays. <br />- Large b...  This is the one of the bests spots in Rio. Bec...                  4.68     en\n",
       "3       17878  137528  2010-11-12         230449         Orene  In general very good and reasonable price.\\r<b...          17878  Very Nice 2Br in Copacabana w. balcony, fast WiFi  Discounts for long term stays. <br />- Large b...  This is the one of the bests spots in Rio. Bec...                  4.68     en\n",
       "4       17878  147594  2010-12-01         219338         David  The apt was nice and in a great location only ...          17878  Very Nice 2Br in Copacabana w. balcony, fast WiFi  Discounts for long term stays. <br />- Large b...  This is the one of the bests spots in Rio. Bec...                  4.68     en"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47cfb3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = self.df['comments'].values\n",
    "        self.y = df['review_scores_rating'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        y = self.y[index]\n",
    "        \n",
    "        inputs_tokenizer = self.tokenizer(\n",
    "                                text,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "        \n",
    "        inputs_ids = inputs_tokenizer['input_ids']\n",
    "        inputs_mask = inputs_tokenizer['attention_mask']\n",
    "           \n",
    "        return {\n",
    "            'inputs_ids': torch.tensor(inputs_ids, dtype=torch.long),\n",
    "            'inputs_mask': torch.tensor(inputs_mask, dtype=torch.long),\n",
    "            'value': torch.tensor(y, dtype=torch.float)\n",
    "            \n",
    "        }\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.fc = nn.Linear(768, 1)\n",
    "        \n",
    "    def forward(self, ids, mask):        \n",
    "        \n",
    "        out = self.model(input_ids=ids,\n",
    "                         attention_mask=mask,\n",
    "                         output_hidden_states=False)\n",
    "            \n",
    "        out = self.drop(out[1])\n",
    "        outputs = self.fc(out)\n",
    "        return outputs\n",
    "\n",
    "def criterion(outputs1, outputs2):  \n",
    "    list_a = []\n",
    "    list_b = []\n",
    "    \n",
    "    outputs1 = torch.flatten(outputs1)\n",
    "    for o in outputs2:\n",
    "        list_b.append(o.item())\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    return loss(outputs1.to(CONFIG['device']), torch.Tensor(list_b).to(CONFIG['device']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6446067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm.notebook as tqdm\n",
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    print(dataloader)\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    \n",
    "    for step, data in bar:\n",
    "        \n",
    "        input_ids = data['inputs_ids'].to(device, dtype = torch.long)\n",
    "        inputs_mask = data['inputs_mask'].to(device, dtype = torch.long)\n",
    " \n",
    "        value = data['value'].to(device)\n",
    "        batch_size = input_ids.size(0)\n",
    "\n",
    "        result = model(input_ids, inputs_mask)\n",
    "        \n",
    "        loss = criterion(result, value)\n",
    "        loss = loss / CONFIG['n_accumulate']\n",
    "        loss.backward()\n",
    "    \n",
    "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
    "            optimizer.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "                \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:        \n",
    "        data_toxic_ids = data['inputs_ids'].to(device, dtype = torch.long)\n",
    "        data_toxic_mask = data['inputs_mask'].to(device, dtype = torch.long)\n",
    "        value = data['value'].to(device)\n",
    "        batch_size = data_toxic_ids.size(0)\n",
    "        result = model(data_toxic_ids, data_toxic_mask)\n",
    "        \n",
    "        loss = criterion(result, value)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])   \n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss\n",
    "\n",
    "def run_training(model, optimizer, scheduler, device, num_epochs, fold):\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_loss = np.inf\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG['device'], epoch=epoch)\n",
    "        \n",
    "        val_epoch_loss = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
    "                                         epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(val_epoch_loss)\n",
    "        \n",
    "        \n",
    "        wandb.log({\"Train Loss\": train_epoch_loss})\n",
    "        wandb.log({\"Valid Loss\": val_epoch_loss})\n",
    "        \n",
    "        if val_epoch_loss <= best_epoch_loss:\n",
    "            print(f\"{b_}Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n",
    "            best_epoch_loss = val_epoch_loss\n",
    "            run.summary[\"Best Loss\"] = best_epoch_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"Loss-Fold-{fold}.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            print(f\"Model Saved{sr_}\")\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6b6c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders(fold):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = ReviewsDataset(df_train, tokenizer=tokenizer, max_length=CONFIG['max_length'])\n",
    "    valid_dataset = ReviewsDataset(df_valid, tokenizer=tokenizer, max_length=CONFIG['max_length'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
    "                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader\n",
    "\n",
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
    "                                                             eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6a9f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "# For Transformer Models\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "b_ = Fore.BLUE\n",
    "y_ = Fore.YELLOW\n",
    "sr_ = Style.RESET_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "746db0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josu/workspace38/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id_x</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>reviewer_id_y</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>idioms</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17878</td>\n",
       "      <td>64852</td>\n",
       "      <td>2010-07-15</td>\n",
       "      <td>135370</td>\n",
       "      <td>Tia</td>\n",
       "      <td>This apartment is in a perfect location -- two...</td>\n",
       "      <td>17878</td>\n",
       "      <td>Very Nice 2Br in Copacabana w. balcony, fast WiFi</td>\n",
       "      <td>Discounts for long term stays. &lt;br /&gt;- Large b...</td>\n",
       "      <td>This is the one of the bests spots in Rio. Bec...</td>\n",
       "      <td>4.68</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17878</td>\n",
       "      <td>76744</td>\n",
       "      <td>2010-08-11</td>\n",
       "      <td>10206</td>\n",
       "      <td>Mimi</td>\n",
       "      <td>we had a really great experience staying in Ma...</td>\n",
       "      <td>17878</td>\n",
       "      <td>Very Nice 2Br in Copacabana w. balcony, fast WiFi</td>\n",
       "      <td>Discounts for long term stays. &lt;br /&gt;- Large b...</td>\n",
       "      <td>This is the one of the bests spots in Rio. Bec...</td>\n",
       "      <td>4.68</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17878</td>\n",
       "      <td>91074</td>\n",
       "      <td>2010-09-06</td>\n",
       "      <td>80253</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Staying in Max appartment is like living in a ...</td>\n",
       "      <td>17878</td>\n",
       "      <td>Very Nice 2Br in Copacabana w. balcony, fast WiFi</td>\n",
       "      <td>Discounts for long term stays. &lt;br /&gt;- Large b...</td>\n",
       "      <td>This is the one of the bests spots in Rio. Bec...</td>\n",
       "      <td>4.68</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17878</td>\n",
       "      <td>137528</td>\n",
       "      <td>2010-11-12</td>\n",
       "      <td>230449</td>\n",
       "      <td>Orene</td>\n",
       "      <td>In general very good and reasonable price.\\r&lt;b...</td>\n",
       "      <td>17878</td>\n",
       "      <td>Very Nice 2Br in Copacabana w. balcony, fast WiFi</td>\n",
       "      <td>Discounts for long term stays. &lt;br /&gt;- Large b...</td>\n",
       "      <td>This is the one of the bests spots in Rio. Bec...</td>\n",
       "      <td>4.68</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17878</td>\n",
       "      <td>147594</td>\n",
       "      <td>2010-12-01</td>\n",
       "      <td>219338</td>\n",
       "      <td>David</td>\n",
       "      <td>The apt was nice and in a great location only ...</td>\n",
       "      <td>17878</td>\n",
       "      <td>Very Nice 2Br in Copacabana w. balcony, fast WiFi</td>\n",
       "      <td>Discounts for long term stays. &lt;br /&gt;- Large b...</td>\n",
       "      <td>This is the one of the bests spots in Rio. Bec...</td>\n",
       "      <td>4.68</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id      id        date  reviewer_id_x reviewer_name                                           comments  reviewer_id_y                                               name                                        description                              neighborhood_overview  review_scores_rating idioms  kfold\n",
       "0       17878   64852  2010-07-15         135370           Tia  This apartment is in a perfect location -- two...          17878  Very Nice 2Br in Copacabana w. balcony, fast WiFi  Discounts for long term stays. <br />- Large b...  This is the one of the bests spots in Rio. Bec...                  4.68     en      0\n",
       "1       17878   76744  2010-08-11          10206          Mimi  we had a really great experience staying in Ma...          17878  Very Nice 2Br in Copacabana w. balcony, fast WiFi  Discounts for long term stays. <br />- Large b...  This is the one of the bests spots in Rio. Bec...                  4.68     en      0\n",
       "2       17878   91074  2010-09-06          80253           Jan  Staying in Max appartment is like living in a ...          17878  Very Nice 2Br in Copacabana w. balcony, fast WiFi  Discounts for long term stays. <br />- Large b...  This is the one of the bests spots in Rio. Bec...                  4.68     en      1\n",
       "3       17878  137528  2010-11-12         230449         Orene  In general very good and reasonable price.\\r<b...          17878  Very Nice 2Br in Copacabana w. balcony, fast WiFi  Discounts for long term stays. <br />- Large b...  This is the one of the bests spots in Rio. Bec...                  4.68     en      1\n",
       "4       17878  147594  2010-12-01         219338         David  The apt was nice and in a great location only ...          17878  Very Nice 2Br in Copacabana w. balcony, fast WiFi  Discounts for long term stays. <br />- Large b...  This is the one of the bests spots in Rio. Bec...                  4.68     en      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=CONFIG['n_fold'], shuffle=True, random_state=CONFIG['seed'])\n",
    "\n",
    "for fold, ( _, val_) in enumerate(skf.split(X=df, y=df['idioms'])):\n",
    "    df.loc[val_ , \"kfold\"] = int(fold)\n",
    "    \n",
    "df[\"kfold\"] = df[\"kfold\"].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96f4b398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m====== Fold: 0 ======\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manony-moose-172447\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/anony-moose-172447/Cognitivo/runs/35asmjop?apiKey=ca2b073b1f5c1c5dcd6456d17fa92ab3c9041ddd\" target=\"_blank\">pretty-durian-22</a></strong> to <a href=\"https://wandb.ai/anony-moose-172447/Cognitivo?apiKey=ca2b073b1f5c1c5dcd6456d17fa92ab3c9041ddd\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 3060\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fb414c27df0>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9232c7bb5e4346b5ac58f54caea392cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8902.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b412effe9724f1883c3d6cf554eba3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=89030.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34mValidation Loss Improved (inf ---> 0.08607730353938059)\n",
      "Model Saved\u001b[0m\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fb414c27df0>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c88ba725984f8cb238b7fa70b5259f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8902.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08172ded1a84aaeaa352c063309c86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=89030.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34mValidation Loss Improved (0.08607730353938059 ---> 0.07338057057049553)\n",
      "Model Saved\u001b[0m\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fb414c27df0>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8855c5586d85488cb74a2b74e28cc6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8902.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5244de2df9b6476fb717930016e11afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=89030.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34mValidation Loss Improved (0.07338057057049553 ---> 0.06936511964845386)\n",
      "Model Saved\u001b[0m\n",
      "\n",
      "Training complete in 4h 8m 32s\n",
      "Best Loss: 0.0694\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4959... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▂▁</td></tr><tr><td>Valid Loss</td><td>█▃▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Loss</td><td>0.06937</td></tr><tr><td>Train Loss</td><td>0.08249</td></tr><tr><td>Valid Loss</td><td>0.06937</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">pretty-durian-22</strong>: <a href=\"https://wandb.ai/anony-moose-172447/Cognitivo/runs/35asmjop?apiKey=ca2b073b1f5c1c5dcd6456d17fa92ab3c9041ddd\" target=\"_blank\">https://wandb.ai/anony-moose-172447/Cognitivo/runs/35asmjop?apiKey=ca2b073b1f5c1c5dcd6456d17fa92ab3c9041ddd</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220320_112451-35asmjop/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33m====== Fold: 1 ======\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/anony-moose-172447/Cognitivo/runs/5ohh2npa?apiKey=ca2b073b1f5c1c5dcd6456d17fa92ab3c9041ddd\" target=\"_blank\">deep-silence-23</a></strong> to <a href=\"https://wandb.ai/anony-moose-172447/Cognitivo?apiKey=ca2b073b1f5c1c5dcd6456d17fa92ab3c9041ddd\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 3060\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fb39d75ba30>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac262c61d16e46309bec1de0eb9e4941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8902.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4e19bd9941400986ac76eba4c090db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=89030.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34mValidation Loss Improved (inf ---> 0.13615218526081727)\n",
      "Model Saved\u001b[0m\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fb39d75ba30>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7527f3dc0146ce8323e7ac1d2bd219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8902.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 60.00 MiB (GPU 0; 11.77 GiB total capacity; 8.48 GiB already allocated; 13.50 MiB free; 9.01 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4813/208041103.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     model, history = run_training(model, optimizer, scheduler,\n\u001b[0m\u001b[1;32m     23\u001b[0m                                   \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                   \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4813/3681922227.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, optimizer, scheduler, device, num_epochs, fold)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n\u001b[0m\u001b[1;32m     85\u001b[0m                                            \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                                            device=CONFIG['device'], epoch=epoch)\n",
      "\u001b[0;32m/tmp/ipykernel_4813/3681922227.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, scheduler, dataloader, device, epoch)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4813/331433884.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids, mask)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         out = self.model(input_ids=ids,\n\u001b[0m\u001b[1;32m     50\u001b[0m                          \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                          output_hidden_states=False)\n",
      "\u001b[0;32m~/workspace38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m         )\n\u001b[0;32m--> 999\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1000\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 )\n\u001b[1;32m    584\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    586\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    514\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         )\n",
      "\u001b[0;32m~/workspace38/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2361\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace38/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace38/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgelu\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m   1457\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 60.00 MiB (GPU 0; 11.77 GiB total capacity; 8.48 GiB already allocated; 13.50 MiB free; 9.01 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import gc\n",
    "for fold in range(0, CONFIG['n_fold']):\n",
    "    print(f\"{y_}====== Fold: {fold} ======{sr_}\")\n",
    "    run = wandb.init(project='Cognitivo', \n",
    "                     config=CONFIG,\n",
    "                     job_type='Train',\n",
    "                     anonymous='must')\n",
    "    \n",
    "    # Create Dataloaders\n",
    "    train_loader, valid_loader = prepare_loaders(fold=fold)\n",
    "    \n",
    "    model = Net(CONFIG['model_name'])\n",
    "    model.to(CONFIG['device'])\n",
    "    \n",
    "    # Define Optimizer and Scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "    \n",
    "    model, history = run_training(model, optimizer, scheduler,\n",
    "                                  device=CONFIG['device'],\n",
    "                                  num_epochs=CONFIG['epochs'],\n",
    "                                  fold=fold)\n",
    "    \n",
    "    \n",
    "    run.finish()\n",
    "    \n",
    "    del model, history, train_loader, valid_loader\n",
    "    _ = gc.collect()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
